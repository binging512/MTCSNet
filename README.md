# MTCSNet: One-stage learning and two-point labeling are sufficient for cell segmentation

## Introduction

This the code of the paper: [TBD]

- MTCSNet is trained in a one-stage manner with only two annotated points for each cell instead of pixel-level annotations.
- Four kinds of labels are generated and five different sub-tasks are elaborately proposed to jointly optimize the MTCSNet.
- Experiments on six public datasets, namely MoNuSeg, TNBC, CPM-17, PanNuke, Lizard and CellSeg, indicate that MTCSNet outperforms all state-of-the-art weakly supervised learning methods.

![](D:\codes\MTCSNet\images\framework_v5.png)

## Instructions

### Installation

1. Download the codes.

```bash
git clone https://github.com/binging512/MTCSNet.git
cd MTCSNet
```

2. Install the requirements.

```bash
pip install -r requirements.txt
```

### Prepare the datasets

1. Download the datasets to ```./data``` directory.
2. Run the preprocessing scripts to remake the datasets and generate pseudo labels (e.g. for MoNuSeg). This process will take some time.

```bash
python preprocess/pre_MoNuSeg.py
```

3. Finally, you can get a dataset directory in a structure like this: (Different datasets may have slightly different file structures.)

```
./data
	├── MoNuSeg						# MoNuSeg dataset
	│   ├── test					# MoNuSeg test set
	│   │   ├── gts					# Ground truth
    │   │	│	├── TCGA-2Z-A9J9-01A-01-TS1.tiff
    │   │	│	└── ...
	│   │   ├── images				# Images
    │   │	│	├── TCGA-2Z-A9J9-01A-01-TS1.tif
    │   │	│	└── ...
	│   │   ├── labels				# Four kinds of labels for full and weak supervision
	│   │	│	├── full			# Full classification labels
	│   │	│	│	├── TCGA-2Z-A9J9-01A-01-TS1.png
	│   │	│	│	└── ...
    │   │	│	├── full_distmap	# Full distance labels
    │   │	│	│	├── TCGA-2Z-A9J9-01A-01-TS1.png
	│   │	│	│	└── ...
    │   │	│	├── full_heatmap	# Full regression labels
    │   │	│	│	├── TCGA-2Z-A9J9-01A-01-TS1.png
	│   │	│	│	└── ...
	│   │	│	├── weak			# Weak classification labels
    │   │	│	│	├── TCGA-2Z-A9J9-01A-01-TS1.png
	│   │	│	│	└── ...
    │   │	│	├── weak_distmap	# Weak distance labels
    │   │	│	│	├── TCGA-2Z-A9J9-01A-01-TS1.png
	│   │	│	│	└── ...
    │   │	│	└── weak_heatmap	# Weak regression labels
	│   │	│		├── TCGA-2Z-A9J9-01A-01-TS1.png
	│   │	│		└── ...
	│   │   ├── points				# Annotated points (cell centroid, boundary and background points)
    │	│	│	├── TCGA-2Z-A9J9-01A-01-TS1.json
    │	│	│	└── ...
	│   │   ├── superpixels			# Superpixels generated by  SLIC0
	│	│	│	├── TCGA-2Z-A9J9-01A-01-TS1.tiff
    │	│	│	└── ...
	│   │   ├── voronois			# Voronoi diagrams
	│	│	│	├── TCGA-2Z-A9J9-01A-01-TS1.png
    │	│	│	└── ...
	│	│	└── ...					# Other directories such as semantics, vis, etc.
	│   └── train					# MoNuSeg training set
    │		└── ...
	├── TNBC						# TNBC dataset
	│	└── ...
	└── ...							# Other datasets
```

4. Generate the split file for training and testing. (Take ```train_mo_val_mo.json``` as an example.) 

```json
{
  "train": [
    {
      "img_path": "./data/MoNuSeg/train/images/TCGA-A7-A13E-01Z-00-DX1.tif",
      "gt_path": "./data/MoNuSeg/train/gts/TCGA-A7-A13E-01Z-00-DX1.tiff",
      "full_label_path": "./data/MoNuSeg/train/labels/full/TCGA-A7-A13E-01Z-00-DX1.png",
      "full_heat_path": "./data/MoNuSeg/train/labels/full_heatmap/TCGA-A7-A13E-01Z-00-DX1.png",
      "weak_label_path": "./data/MoNuSeg/train/labels/weak/TCGA-A7-A13E-01Z-00-DX1.png",
      "weak_heat_path": "./data/MoNuSeg/train/labels/weak_heatmap/TCGA-A7-A13E-01Z-00-DX1.png",
      "semantic_path": "./data/MoNuSeg/train/semantics/TCGA-A7-A13E-01Z-00-DX1.png",
      "point_path": "./data/MoNuSeg/train/points/TCGA-A7-A13E-01Z-00-DX1.json"
    },
    	...
    ],
  "val": [
    {
      "img_path": "./data/MoNuSeg/test/images/TCGA-ZF-A9R5-01A-01-TS1.tif",
      "gt_path": "./data/MoNuSeg/test/gts/TCGA-ZF-A9R5-01A-01-TS1.tiff",
      "full_label_path": "./data/MoNuSeg/test/labels/full/TCGA-ZF-A9R5-01A-01-TS1.png",
      "full_heat_path": "./data/MoNuSeg/test/labels/full_heatmap/TCGA-ZF-A9R5-01A-01-TS1.png",
      "weak_label_path": "./data/MoNuSeg/test/labels/weak/TCGA-ZF-A9R5-01A-01-TS1.png",
      "weak_heat_path": "./data/MoNuSeg/test/labels/weak_heatmap/TCGA-ZF-A9R5-01A-01-TS1.png",
      "semantic_path": "./data/MoNuSeg/test/semantics/TCGA-ZF-A9R5-01A-01-TS1.png",
      "point_path": "./data/MoNuSeg/test/points/TCGA-ZF-A9R5-01A-01-TS1.json"
    },
	    ...
    ],
}
```

### Customize the config files (Not necessary)

1. Custom the config files as you like, or you can use our ```.yaml``` config files.
2. And you can get a config file like this. (Take ```./configs/MoNuSeg/Mo_Mo_cls2_unet50rvdc_1head_ep500_b4_crp512_iter0_cn.yaml``` as an example.)

```yaml
# Dataset
data_type: 'CellSeg'									# Used for selecting the dataset codes
train_mode: 'train_weak'								# Dataset mode: 'train_full', 'train_weak'
test_mode: 'val'										# Testing split
data_root: './data'										# Data root
split_info: './data/splits/train_mo_val_mo.json'		# Split files

test_image_dir: './data/'
test_anno_dir: './data/'

batch_size: 4
num_worker: 4

# Augmentation
scale_range: [0.5,3.0]									# Random scale range
crop_size: [512, 512]									# Random crop size
rand_flip: 0.5											# Probility of random flipping
rand_rotate: True
rand_bright: 0											# Colorjitter
rand_contrast: 0
rand_saturation: 0
rand_hue: 0
cutmix: False											# Cutmix (default False)
beta: 1.0												# Parameter beta for Cutmix
cutmix_prob: 0.5
degree_version: 'v10'									# The version of Distance loss
degree_neighbour: 1
distance_scale: 1
count_scale: 100
pesudo_rate: 0

# Net
net_name: 'unet'										# Network for segmentation
net_backbone: 'resnet50'
net_num_classes: 2										# Number of segmentation classes
net_nheads: 1											# Number of heads in the last segmentation module
net_consistency: True									# L_{con}
net_vorloss: True										# L_{cls}^{vor}
net_convtranspose: False
net_certainty: True										# L_{cls}^{lts}
net_regression: True									# L_{reg}^{sp}
net_reg_weight: 1
net_degree: True										# L_{dis}
net_N: 10
net_count: False
net_num_epoches: 500
net_learning_rate: 0.001
net_celoss: True										# L_{cls}^{sp}
net_diceloss: True
net_focalloss: False
net_resume: False										# Resume training path

# Inference
infer_stride: [256,256]									# Inference slide window stride
infer_threshold: 0.5									# Postprocessing threshold for cell region
infer_seed: 0.8											# Postprocessing threshold for seed region
infer_min_area: 64										# Postprocessing threshold for min area
test_multi_scale: [1.0]									# Multi-scale testing, e.g. [1.0, 1.2] is for 1.0x and 1.5x scales
test_fusion: 'mean'										# Multi-scale tesing fusion mode, ["mean", "max"]
test_degree: 0

# Saving
workspace: './workspace/MoNuSeg_ablation/Mo_Mo_unet50rvdc_cls2_1head_ep500_b4_crp512_iter0_cn'	# The root of saving directory 
results_val: 'results_val'								# Saving directory for validation
results_test: 'results_test'							# Saving directory for test
checkpoint: checkpoints/epoch_450.pth					# Testing model
val_interval: 5
save_interval: 100
```

### Train and test the model

1. After setup all the process, you can train the model with this command.

```bash
CUDA_VISIBLE_DEVICES=0 python run.py --train_pass True --config <path_to_your_config>
```

2. After training the model, you can test the model with this command.

```bash
CUDA_VISIBLE_DEVICES=0 python run.py --test_pass True --config <path_to_your_config>
```

3. Or, you can train and test the model with a single command.

```bash
CUDA_VISIBLE_DEVICES=0 python run.py --train_pass True --test_pass True --config <path_to_your_config>
```

4. For all the ablation studies in the paper, we provide `.sh` files to run the experiments.

```bash
CUDA_VISIBLE_DEVICES=0 bash scripts/MoNuSeg_ablation.sh
```



## Citation

```latex

```



